groups:
- name: cortex-nova-alerts
  rules:
  - alert: CortexNovaInitialPlacementDown
    expr: |
      up{component="cortex-nova-scheduler", namespace="cortex-nova"} != 1 or
      absent(up{component="cortex-nova-scheduler", namespace="cortex-nova"})
    for: 5m
    labels:
      context: liveness
      dashboard: cortex/cortex
      service: cortex
      severity: warning
      support_group: workload-management
      playbook: docs/support/playbook/cortex/down
    annotations:
      summary: "Cortex initial placement for Nova is down"
      description: >
        The Cortex initial placement service is down. Initial placement requests from Nova will
        not be served. This is no immediate problem, since Nova will continue
        placing new VMs. However, the placement will be less desirable.

  - alert: CortexNovaSyncerDown
    expr: |
      up{component="cortex-nova-syncer", namespace="cortex-nova"} != 1 or
      absent(up{component="cortex-nova-syncer", namespace="cortex-nova"})
    for: 5m
    labels:
      context: liveness
      dashboard: cortex/cortex
      service: cortex
      severity: warning
      support_group: workload-management
    annotations:
      summary: "Cortex syncer is down"
      description: >
        The Cortex syncer is down. Cortex requires somewhat recent data from
        it's datasources (OpenStack, Prometheus, etc.) to make accurate
        scheduling decisions. If this issue persists for a longer time, the
        data based will slowly drift away from the actual state of the
        datacenter, which may lead to less desirable placement decisions.
        This is no immediate problem, since Nova will continue placing new VMs.

  - alert: CortexNovaExtractorDown
    expr: |
      up{component="cortex-nova-extractor", namespace="cortex-nova"} != 1 or
      absent(up{component="cortex-nova-extractor", namespace="cortex-nova"})
    for: 5m
    labels:
      context: liveness
      dashboard: cortex/cortex
      service: cortex
      severity: warning
      support_group: workload-management
    annotations:
      summary: "Cortex extractor is down"
      description: >
        The Cortex extractor is down. This means that newly available data
        about the datacenter will not be used to extract scheduling knowledge.
        This is no immediate problem, since Nova will continue placing new VMs.
        However, the placement will be less desirable.

  - alert: CortexNovaDeschedulerPipelineErroring
    expr: delta(cortex_descheduler_pipeline_vm_descheduling_duration_seconds_count{component=~"cortex-nova-.*", error="true", namespace="cortex-nova"}[2m]) > 0
    for: 5m
    labels:
      context: descheduler
      dashboard: cortex/cortex
      service: cortex
      severity: warning
      support_group: workload-management
    annotations:
      summary: "Descheduler pipeline is erroring."
      description: >
        The Cortex descheduler pipeline is encountering errors during its execution.
        This may indicate issues with the descheduling logic or the underlying infrastructure.
        It is recommended to investigate the descheduler logs and the state of the VMs being processed.

  - alert: CortexNovaHostCPUAvailableCapacityBelow0Percent
    expr: cortex_sap_available_capacity_per_host_pct{component=~"cortex-nova-.*", resource="cpu", namespace="cortex-nova"} < 0
    for: 5m
    labels:
      context: availablecapacity
      dashboard: cortex/cortex
      service: cortex
      severity: info
      support_group: workload-management
    annotations:
      summary: "CPU available capacity on host `{{$labels.compute_host_name}}` is below 0%"
      description: >
        OpenStack Placement reports CPU available capacity below 0% for host `{{$labels.compute_host_name}}` in AZ `{{$labels.availability_zone}}` for over 5 minutes.
        This can happen if there are VMs in the SHUTOFF state: these VMs still consume resources in Placement, but not in the underlying infrastructure (e.g., VMware). As a result, it is possible to manually migrate additional VMs onto a host with shut off VMs. The combined resource allocation (from running and shut off VMs) can then exceed the host's capacity, causing Placement to report available capacity below 0%. This is expected behavior, as powering on the shut off VMs would overcommit the host.
        Another cause may be shutting down a node without migrating its VMs. The total capacity drops, but Placement still accounts for the shut off VMs’ resource usage.
        This situation should be investigated and resolved to ensure accurate resource accounting and avoid operational issues.

  - alert: CortexNovaHostMemoryAvailableCapacityBelow0Percent
    expr: cortex_sap_available_capacity_per_host_pct{component=~"cortex-nova-.*", resource="memory", namespace="cortex-nova"} < 0
    for: 5m
    labels:
      context: availablecapacity
      dashboard: cortex/cortex
      service: cortex
      severity: info
      support_group: workload-management
    annotations:
      summary: "Memory available capacity on host `{{$labels.compute_host_name}}` is below 0%"
      description: >
        OpenStack Placement reports Memory available capacity below 0% for host `{{$labels.compute_host_name}}` in AZ `{{$labels.availability_zone}}` for over 5 minutes.
        This can happen if there are VMs in the SHUTOFF state: these VMs still consume resources in Placement, but not in the underlying infrastructure (e.g., VMware). As a result, it is possible to manually migrate additional VMs onto a host with shut off VMs. The combined resource allocation (from running and shut off VMs) can then exceed the host's capacity, causing Placement to report available capacity below 0%. This is expected behavior, as powering on the shut off VMs would overcommit the host.
        Another cause may be shutting down a node without migrating its VMs. The total capacity drops, but Placement still accounts for the shut off VMs’ resource usage.
        This situation should be investigated and resolved to ensure accurate resource accounting and avoid operational issues.

  - alert: CortexNovaHostDiskAvailableCapacityBelow0Percent
    expr: cortex_sap_available_capacity_per_host_pct{component=~"cortex-nova-.*", resource="disk", namespace="cortex-nova"} < 0
    for: 5m
    labels:
      context: availablecapacity
      dashboard: cortex/cortex
      service: cortex
      severity: info
      support_group: workload-management
    annotations:
      summary: "Disk available capacity on host `{{$labels.compute_host_name}}` is below 0%."
      description: >
        OpenStack Placement reports Disk available capacity below 0% for host `{{$labels.compute_host_name}}` in AZ `{{$labels.availability_zone}}` for over 5 minutes.
        This can happen if there are VMs in the SHUTOFF state: these VMs still consume resources in Placement, but not in the underlying infrastructure (e.g., VMware). As a result, it is possible to manually migrate additional VMs onto a host with shut off VMs. The combined resource allocation (from running and shut off VMs) can then exceed the host's capacity, causing Placement to report available capacity below 0%. This is expected behavior, as powering on the shut off VMs would overcommit the host.
        Another cause may be shutting down a node without migrating its VMs. The total capacity drops, but Placement still accounts for the shut off VMs’ resource usage.
        This situation should be investigated and resolved to ensure accurate resource accounting and avoid operational issues.
